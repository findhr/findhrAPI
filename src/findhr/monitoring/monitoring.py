from collections import defaultdict
import csv
import sys
import random
import base64
import json
from mpyc.runtime import mpc
from cryptography.hazmat.primitives.asymmetric import padding
from cryptography.hazmat.primitives import hashes
import matplotlib.pyplot as plt
import numpy as np
import math
from scipy.stats import norm


SENSITIVE_ATTRIBUTE_CATALOGUE = {
    'gender': {"male": 0, "female": 1, "non-binary": 2},
    'disabled': {"True": 1, "False": 0}
}



class MultipartyDataCollection():

    """
    Base handler for managing the collection and multiparty storage of protected attributes.
    
    """

    def generate_multiparty_data(self, provider_id, user_id, attribute_name, attribute_value):
        """
        Generate two secret multiparty components of a protected attribute.


        Parameters
        ----------
        provider_id : string
            The identifier of the service provider

        user_id : string
            The identifier of the user generated by the service provider
            when the user is redirected from a succesful job application to optional attribute donation

        attribute_name : string
            The name of the attribute to measure diversity for, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        attribute_value : string
            The value of the selected attribute_name, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        Returns
        -------
        protected_attribute_components: (int, int)
           Multiparty components of the protected attribute (remote, local).
        """

        random.seed()
        # generate dynamic ranges for secret generation
        # todo in future versions: edge values are unlikely but might reveal the sensitive attribute
        secret = random.randint(
            -(sys.maxsize - len(SENSITIVE_ATTRIBUTE_CATALOGUE[attribute_name])) - 1, 
            sys.maxsize - len(SENSITIVE_ATTRIBUTE_CATALOGUE[attribute_name]))

        protected_attribute = SENSITIVE_ATTRIBUTE_CATALOGUE[attribute_name][attribute_value]

        # # todo: what happens here if one of the transactions fail
        # self.send_to_model_owner(provider_id, user_id, attribute_name, protected_attribute - secret)
        # self.store(provider_id, user_id, attribute_name, protected_attribute + secret)

        return (protected_attribute + secret, protected_attribute - secret)


    def send_to_model_owner(self, provider_id, user_id, attribute_name, secret_protected_attribute):
        """
        This is an empty placeholder: the third party needs to reimplement it 
        to send the secret attribute component to the remote service provider
        """
        pass


    def store(self, provider_id, user_id, attribute_name, secret_protected_attribute):
        """
        This is an empty placeholder: the third party should reimplement it 
        to save the secret attribute component in their local storage (e.g., a database)
        """
        pass





class MultipartyDataHandlerCSV(MultipartyDataCollection):

    """
    Example handler for managing the collection and multiparty storage of protected attributes. 
    Uses CSV files for local data storage.

    After a session of data updates, save_session_data needs to be called to save the changes the drive.

    Attributes
    ----------
    local_filename : string
        Name of a csv file to load data from, and save data to.
        The file contains rows of the following comma-separated values: provider id, user id, attribute name, secret value.

    local_data : defaultdict[defaultdict[defaultdict[int]]
        A temporary dictionary for handling the local data. Has the following levels: local_data[provider_id][user_id][attribute_value] = secret_value.

    """


    def __init__(self, local_filename):

        self.local_filename = local_filename
        self.load_data(local_filename)


    def load_data(self, local_filename):

        """
        Loads data from the local_filename csv file into self.local_data

        Parameters
        ----------
        local_filename : string 
            Name of a csv file to load data from.
        """

        # This creates a dictionary with three level key acess:
        #    provider ID -> user ID -> attribute name -> local secret value
        self.local_data = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))

        with open(local_filename, 'r') as f_in:
            reader = csv.reader(f_in, delimiter=',')

            for row in reader:
                # provider ID -> user ID -> attribute name -> local secret value
                if len(row) == 4:
                    self.local_data[row[0]][row[1]][row[2]] = int(row[3])


    def save_session_data(self):

        """
        Writes data from self.local_data dictionary to the self.local_filename csv file.
        """

        with open(self.local_filename, 'w') as f_out:

            writer =csv.writer(f_out, delimiter=',')

            for provider_id in self.local_data.keys():
                for user_id in self.local_data[provider_id].keys():
                    for attribute_name in self.local_data[provider_id][user_id].keys():
                        secret_value = self.local_data[provider_id][user_id][attribute_name]
                        writer.writerow([provider_id, user_id, attribute_name, secret_value])


    def send_to_model_owner(self, provider_id, user_id, attribute_name, secret_protected_attribute, provider_handler):
        """
        This is an example placeholder: the third party needs to reimplement it 
        to send the secret attribute component to the remote service provider.
        Current example immplementation: calls the 'receive' function of an instantiated service provider handler (ServiceProviderHandlerCSV)

        Parameters
        ----------
        provider_id : string
            The identifier of the service provider

        user_id : string
            The identifier of the user generated by the service provider
            when the user is redirected from a succesful job application to optional attribute donation

       attribute_name : string
            The name of the attribute to measure diversity for, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        secret_protected_attribute : int
            Randomized component of the protected attribute value

        provider_handler : ServiceProviderHandlerCSV instance
            instance of a service provider data handler (e.g., ServiceProviderHandlerCSV)
        """
        provider_handler.receive(provider_id, user_id, attribute_name, secret_protected_attribute)


    def store(self, provider_id, user_id, attribute_name, secret_protected_attribute):
        """
        Store the local component of the secret attribute into the temporary self.local_data dictionary.

        Parameters
        ----------
        provider_id : string
            The identifier of the service provider

        user_id : string
            The identifier of the user generated by the service provider
            when the user is redirected from a succesful job application to optional attribute donation

       attribute_name : string
            The name of the attribute to measure diversity for, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        secret_protected_attribute : int
            Randomized component of the protected attribute value
        """
        self.local_data[provider_id][user_id][attribute_name] = secret_protected_attribute


    def decrypt_data(self, encrypted_data, private_key):
        """
        RSA decryption and decoding to dictionary.
        """
        decoded_data = base64.b64decode(encrypted_data)
        decrypted_data = private_key.decrypt(
            decoded_data,
            padding.OAEP(mgf=padding.MGF1(algorithm=hashes.SHA256()), algorithm=hashes.SHA256(), label=None)
        )
        return json.loads(decrypted_data.decode('utf-8'))

    
    def store_encrypted_data(self, encrypted_data, private_key):

        """
        decrypt and decode data and save session data
        """
        try:
            data_dict = self.decrypt_data(encrypted_data, private_key)
        except Exception as e:
            return {"error": f"Decryption failed: {str(e)}"}

        provider_id = data_dict.get("providerId")
        user_id = data_dict.get("userId")

        if not provider_id or not user_id:
            return {"error": "Invalid data format"}

        for attribute_name, secret_value in data_dict.items():
            if attribute_name not in ["providerId", "userId"]:
                self.store(provider_id, user_id, attribute_name, secret_value)

        # store and reset
        self.save_session_data()

class ServiceProviderHandlerCSV():

    """
    Example handler for managing the storage of secret protected attribute components by a service provider. 
    Uses CSV files for local data storage.

    After a session of data updates, save_session_data needs to be called to save the changes the drive.

    Attributes
    ----------
    local_filename : string
        Name of a csv file to load data from, and save data to.
        The file contains rows of the following comma-separated values: provider id, user id, attribute name, secret value.

    local_data : defaultdict[defaultdict[defaultdict[int]]
        A temporary dictionary for handling the local data. Has the following levels: local_data[provider_id][user_id][attribute_value] = secret_value.

    """

    def __init__(self, local_filename):
        self.local_filename = local_filename

        # This creates a dictionary with three level key acess:
        #    provider ID -> user ID -> attribute name -> local secret value
        self.local_data = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))

        with open(local_filename, 'r') as f_in:
            reader = csv.reader(f_in, delimiter=',')

            for row in reader:
                # provider ID -> user ID -> attribute name -> local secret value
                if len(row) == 4:
                    self.local_data[row[0]][row[1]][row[2]] = int(row[3])


    def receive(self, provider_id, user_id, attribute_name, secret_protected_attribute):

        """
        This is an example placeholder: the service provider needs to reimplement it 
        to handle the receipt of the radomized sensitive attribute component within their infrastructure.

        Parameters
        ----------
        provider_id : string
            The identifier of the service provider

        user_id : string
            The identifier of the user generated by the service provider
            when the user is redirected from a succesful job application to optional attribute donation

       attribute_name : string
            The name of the attribute to measure diversity for, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        secret_protected_attribute : int
            Randomized component of the protected attribute value

        """

        self._store(provider_id, user_id, attribute_name, secret_protected_attribute)


    def _store(self, provider_id, user_id, attribute_name, secret_protected_attribute):
        """
        Store the local component of the secret attribute.
        """
        self.local_data[provider_id][user_id][attribute_name] = secret_protected_attribute


    def save_session_data(self):

        """
        Writes data from self.local_data dictionary to the self.local_filename csv file.
        """

        with open(self.local_filename, 'w') as f_out:

            writer =csv.writer(f_out, delimiter=',')

            for provider_id in self.local_data.keys():
                for user_id in self.local_data[provider_id].keys():
                    for attribute_name in self.local_data[provider_id][user_id].keys():
                        secret_value = self.local_data[provider_id][user_id][attribute_name]
                        writer.writerow([provider_id, user_id, attribute_name, secret_value])


    def decrypt_data(self, encrypted_data, private_key):
        """
        RSA decryption and decoding to dictionary.
        """
        decoded_data = base64.b64decode(encrypted_data)
        decrypted_data = private_key.decrypt(
            decoded_data,
            padding.OAEP(mgf=padding.MGF1(algorithm=hashes.SHA256()), algorithm=hashes.SHA256(), label=None)
        )
        return json.loads(decrypted_data.decode('utf-8'))

    
    def store_encrypted_data(self, encrypted_data, private_key):
        """
        decrypt and decode data and save session data
        """
        try:
            data_dict = self.decrypt_data(encrypted_data, private_key)
        except Exception as e:
            return {"error": f"Decryption failed: {str(e)}"}

        provider_id = data_dict.get("providerId")
        user_id = data_dict.get("userId")

        if not provider_id or not user_id:
            return {"error": "Invalid data format"}

        for attribute_name, secret_value in data_dict.items():
            if attribute_name not in ["providerId", "userId"]:
                self._store(provider_id, user_id, attribute_name, secret_value)

        # store and reset
        self.save_session_data()
    
    




class MultipartyFairnessMeasurement():

    """
    Handler for managing the the measurement of fairness in a multi-party regime. 
    The protected attribute components are stored in two places: locally with the third party, and remotely with the service provider.
    Summing the two components allows the third party to recreate the value of the sensitive attribute.
    
    """


    def __init__(self, api_key, data_handler):

        if self._authenticate(api_key):
            self.model_owner_id = api_key

        else:
            raise Exception("Could not authenticate model owner")

        self.data_handler = data_handler


    def _authenticate(self, api_key):
        """
        This is a placeholder: the third party should reimplement it 
        to check whether the provider's ID (e.g., an API key) is OK
        """
        return 1


    def _get_internal_secret(self, user_id, attribute_name):
        """
        This is a placeholder: the third party should reimplement it 
        to retrieve secret attribute components from their storage (e.g., a database)
        """

        # For now, we assume all the data is available. 
        # Missing data will be handled in future versions of the library
        return self.data_handler.local_data[self.model_owner_id][user_id][attribute_name]


    def _desecretize_attribute(self, user_id, attr_secr, attribute_name):

        # This function sums the local and remote components of the protected attribute x.
        # Since components were generated as follows: local = x + secr; remote = x - secr,
        # summing them up gives us 2x -> hence the division by 2.

        if isinstance(attr_secr, dict):
            attr_secr = attr_secr[attribute_name]
        return (attr_secr + self._get_internal_secret(user_id, attribute_name)) / 2


    def _reconstruct_attributes(self, pool, attribute_name):
        return [(user_id, self._desecretize_attribute(user_id, attr_secr, attribute_name)) 
            for (user_id, attr_secr) in pool]


    def _get_num_attribute_value(self, attribute_name, attribute_value):
        """
        This is a placeholder: the third party should reimplement it to match their attribute catalogue
        """

        return SENSITIVE_ATTRIBUTE_CATALOGUE[attribute_name][attribute_value]


    def _get_desecritized_attribute_pool(self, user_pool, attribute_names):
        # desecritize multiple attributes 
        dict_desecr = {}
        for attribute_name in attribute_names:
            pool_desecr = self._reconstruct_attributes(user_pool, attribute_name)
            dict_desecr[attribute_name] = {}
            for user_id, attr in pool_desecr:
                dict_desecr[attribute_name][user_id] = attr
        return dict_desecr
    

    def _check_user_attributes(self, user_id, attribute_names, attribute_values, attribute_desecr_dict):
        # checks if all attribute values apply to the user
        mult = 1
        for attribute_name, attribute_value in zip(attribute_names, attribute_values):
            mult *= attribute_desecr_dict[attribute_name][user_id] == self._get_num_attribute_value(attribute_name, attribute_value)
        return mult
    

    def _assert_pool_attribute_names_values(self, pool, attribute_names, attribute_values, conditionals=None):
        #assertions
        if not isinstance(attribute_names, list) and not isinstance(attribute_names, tuple):
            attribute_names = [attribute_names]
        if not isinstance(attribute_values, list) and not isinstance(attribute_values, tuple):
            attribute_values = [attribute_values]

        assert len(attribute_names) == len(attribute_values), "Number of attribute names must be equal to the number of values"

        for idx, attribute_name in enumerate(attribute_names):
            assert attribute_name in SENSITIVE_ATTRIBUTE_CATALOGUE, f"Attribute '{attribute_name}' not in catalogue"
            attribute_value = attribute_values[idx]
            assert attribute_value in SENSITIVE_ATTRIBUTE_CATALOGUE[attribute_name], f"Value '{attribute_value}' not valid for attribute '{attribute_name}'"

        if conditionals: 
            assert (len(pool) == len(conditionals)), "Size of the conditionals array needs to be equal to the size of the pool"
            pool = [p for p, cond in zip(pool, conditionals) if cond]

        return pool, attribute_names, attribute_values

    def measure_pool_diversity(self, pool, attribute_names, attribute_values, conditionals=None):
        """
        Input fairness metric.
        Measures the fraction of members of a given protected group in a candidate pool (pool diversity).
        

        Parameters
        ----------
        pool : [(string, int)]
            A list of candidates: an unordered list of pairs (user_id, secret_attribute_remote), 
            where the user_id is the user ID generated by the service provider during attribute donation,
            and secret_attribute_remote is the protected attribute component stored by the service provider.

        attribute_names : [string] | (string) | string
            The names/name of the attributes/attribute to measure diversity for, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        attribute_values : [string] | (string) | string
            The values/value of the selected attributes in attribute_names in the same order, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        conditionals : [bool], optional
            (Optional) A list indicating whether individuals at a given position in the pool should be included in the computation. 
            The implementation assumes that len(pool) == len(conditionals).
    
        Returns
        -------
        pool_diversity : float
            The fraction of the members of a selected group in the candidate pool. 
            A float number in the [0,1] range.
        """

        pool, attribute_names, attribute_values = self._assert_pool_attribute_names_values(pool, attribute_names, attribute_values, conditionals)

        dict_desecr = self._get_desecritized_attribute_pool(pool, attribute_names)
        
        return float(len([user_id for (user_id, attr) in pool if self._check_user_attributes(user_id, attribute_names, attribute_values, dict_desecr)])) / len(pool) if pool else 0


    def _normalize_browsing_model(self, browsing_model_weights):
        s = sum(browsing_model_weights)
        return [float(x)/s for x in browsing_model_weights]

    def _generate_browsing_model(self, model_name, length, param=None):
        if model_name == 'inverse_log':
            return [1 / math.log2(i + 2) for i in range(length)]
        elif model_name == 'exp_decay':
            gamma = param if param is not None else 0.8
            return [gamma ** i for i in range(length)]
        else:
            raise ValueError(f"Unsupported browsing model: {model_name}")

    def measure_group_exposure(self, pool, attribute_names, attribute_values, browsing_model, conditionals=None, browsing_param=None):
        """
        Output fairness metric. 
        Measures the exposure of members of a given protected group in a given ranking under a selected browsing model.
        

        Parameters
        ----------
        pool : [(string, int)]
            A ranked list of candidates: an ordered list of pairs (user_id, secret_attribute_remote), 
            where the user_id is the user ID generated by the service provider during attribute donation,
            and secret_attribute_remote is the protected attribute component stored by the service provider.

        attribute_names : [string] | (string) | string
            The names/name of the attributes/attribute to measure group exposure for, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        attribute_values : [string] | (string) | string
            The values/value of the selected attributes in attribute_names in the same order, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        browsing_model : [float] or string
            A browsing behavior model indicating the exposure weights across ranking positions (will be normalized to sum to 1). This can be:
                - A list of floats, where each value represents the exposure weight at a given position
                - A string specifying a predefined model:
                    'inverse_log' — assigns exposure proportionally to 1 / log2(position + 2)
                    'exp_decay' — assigns exposure proportionally to gamma^position (gamma is specified via `browsing_param`, default 0.8)

        conditionals : [bool], optional
            (Optional) A list indicating whether individuals at a given position in the pool should be included in the computation. 
            The implementation assumes that len(pool) == len(conditionals).
        
        browsing_param : float, optional
            (Optional) parameter to customize browsing model, such as gamma for exp_decay
        
        Returns
        -------
        group_exposure : float
            The fraction of exposure the members of a selected group in the candidate pool get in a given ranking. 
            A float number in the [0,1] range.
        """

        pool, attribute_names, attribute_values = self._assert_pool_attribute_names_values(pool, attribute_names, attribute_values, conditionals)

        if isinstance(browsing_model, str):
            browsing_model = self._generate_browsing_model(browsing_model, len(pool), browsing_param)

        if len(browsing_model) < len(pool):
            browsing_model.extend([0] * (len(pool) - len(browsing_model)))
        
        browsing_model = self._normalize_browsing_model(browsing_model)

        ranking_desecr = self._get_desecritized_attribute_pool(pool, attribute_names)

        return sum([
            browsing_model[idx] * int(self._check_user_attributes(cand, attribute_names, attribute_values, ranking_desecr))
                for idx, (cand, attr) in enumerate(pool)
        ])

    def measure_topk_fairness(self, pool, attribute_names, attribute_values, k, method="skew", conditionals=None, epsilon=1e-10):
        """
        Output fairness metric.
        Supports top-k group fairness metrics including skew and discounted representation difference.

        Parameters
        ----------
        pool : [(string, int)]
            A ranked list of candidates: an ordered list of pairs (user_id, secret_attribute_remote), 
            where the user_id is the user ID generated by the service provider during attribute donation,
            and secret_attribute_remote is the protected attribute component stored by the service provider.

        attribute_names : [string] | (string) | string
            The names/name of the attributes/attribute to measure top-k fairness for, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        attribute_values : [string] | (string) | string
            The values/value of the selected attributes in attribute_names in the same order, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        k : int
            The cutoff rank (e.g., top-10 means k=10).

        method : string
            The fairness metric to compute. Supported options:
                - "skew" : Log ratio between group representation in top-k and expected distribution.
                - "discounted_rep_diff" : Difference in discounted representation across ranks.

        conditionals : [bool], optional
            (Optional) A list indicating whether individuals at a given position in the pool should be included in the computation. 
            The implementation assumes that len(pool) == len(conditionals).

        epsilon : float, optional
            (Optional) Small value to avoid division by zero or log(0).

        Returns
        -------
        topk_fairness : float
            The top-k fairness metric for the specified method.
        """

        pool, attribute_names, attribute_values = self._assert_pool_attribute_names_values(pool, attribute_names, attribute_values, conditionals)
        ranking_desecr = self._get_desecritized_attribute_pool(pool, attribute_names)
        top_k_pool = pool[:k]

        def is_in_group(candidate):
            return self._check_user_attributes(candidate, attribute_names, attribute_values, ranking_desecr)

        group_indices = [is_in_group(cand) for cand, _ in pool]
        topk_group_indices = [is_in_group(cand) for cand, _ in top_k_pool]

        total_group_ratio = sum(group_indices) / len(pool) if pool else 0
        topk_group_ratio = sum(topk_group_indices) / k if k > 0 else 0

        if method == "skew":
            numerator = topk_group_ratio + epsilon
            denominator = total_group_ratio + epsilon
            return math.log(numerator / denominator)

        elif method == "discounted_rep_diff":
            drd = 0.0
            for idx, (cand, _) in enumerate(top_k_pool):
                pos = idx + 1
                group_val = 1 if is_in_group(cand) else -1
                drd += group_val / math.log2(pos + 1)
            return drd

        else:
            raise ValueError(f"Unsupported top-k fairness method: {method}")


    def measure_accept_rate(self, pool, pool_stage, attribute_names, attribute_values, conditionals=None):
        """
        Outcome fairnss metric. 
        For demographic parity, measure the proportion of individuals from a given protected group who are finally accepted (accept rate).
        For equal opportunity, measure the proportion of qualified individuals from a given protected group who are correctly classified (true positive rate).
        
        Parameters
        ----------
        pool : [(string, int)]
            A list of candidates: an unordered list of pairs (user_id, secret_attribute_remote), 
            where the user_id is the user ID generated by the service provider during attribute donation,
            and secret_attribute_remote is the protected attribute component stored by the service provider.

        pool_stage : [(string, bool, bool)]
            A pool of candidates: an unordered list of pairs (user_id, targeted, accepted), 
            where the user_id is the user ID corresponding to the pool,
            targeted is True/False indicating whether the candidate is selected as a target, 
            and accepted is True/False indicating whether the candidate actually receives positive outcomes.
            Example for demographic parity: 
                targeted: all set 1, to include all potential candidates; 
                accepted: final interview or recruitment decisions.
            Example for equal opportunity: 
                targeted: whether the candidate is qualified or not, e.g., based on evaluations by a group of experts; 
                accepted: final interview or recruitment decisions.

        attribute_names : [string] | (string) | string
            The names/name of the attributes/attribute to measure outcome fairness for, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        attribute_values : [string] | (string) | string
            The values/value of the selected attributes in attribute_names in the same order, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        conditionals : [bool], optional
            (Optional) A list indicating whether individuals at a given position in the pool should be included in the computation. 
            The implementation assumes that len(pool) == len(conditionals).
        
        Returns
        -------
        accept rate : float
            The fraction of the members of a selected group who receive positive outcomes. 
            A float number in the [0,1] range.
        """
        
        pool, attribute_names, attribute_values = self._assert_pool_attribute_names_values(pool, attribute_names, attribute_values, conditionals)
        
        if conditionals:
            assert len(pool) == len(conditionals), "Size of conditionals array needs to be equal to the size of the pool"
            pool = [p for p, cond in zip(pool, conditionals) if cond]
            pool_stage = [ps for ps, cond in zip(pool_stage, conditionals) if cond]

        dict_desecr = self._get_desecritized_attribute_pool(pool, attribute_names)

        selected_group = [user_id for user_id, attr in pool if self._check_user_attributes(user_id, attribute_names, attribute_values, dict_desecr)]
        
        if len(pool_stage[0]) == 2:
            # only one bool given - set targeted as 1 by default
            stage_dict = {user: (1, accepted) for user, accepted in pool_stage}
        elif len(pool_stage[0]) == 3:
            stage_dict = {user: (targeted, accepted) for user, targeted, accepted in pool_stage}
        else:
            raise ValueError(f"wrong pool stage length: {len(pool_stage[0])}")
        count_actual_positive = 0
        count_true_positive = 0
        
        # Check how many of the selected group reached the interview stage and then got the offer
        for user_id in selected_group:
            targeted, accepted = stage_dict.get(user_id, (False, False))
            
            if targeted:
                count_actual_positive += 1
                if accepted:
                    count_true_positive += 1
        
        equal_opportunity = count_true_positive / count_actual_positive if count_actual_positive else 0
        
        return equal_opportunity


class MultipartyFairnessMeasurementMPYC():

    """
    Handler for managing the the measurement of fairness in a multi-party regime supported by mpyc library. 
    The protected attribute components are stored in two parties.
    Two-party computation enables the monitoring of fairness metrics without reconstructing sensitive attributes.
    
    """


    def __init__(self, api_key, data_handler):

        if self._authenticate(api_key):
            self.provider_id = api_key

        else:
            raise Exception("Could not authenticate model owner")

        self.data_handler = data_handler


    def _authenticate(self, api_key):
        """
        This is a placeholder: the third party should reimplement it 
        to check whether the provider's ID (e.g., an API key) is OK
        """
        return 1
    
    def _get_internal_secret(self, user_id, attribute_name):
        """
        This is a placeholder: the third party should reimplement it 
        to retrieve secret attribute components from their storage (e.g., a database)
        """

        # For now, we assume all the data is available. 
        return self.data_handler.local_data[self.provider_id][user_id][attribute_name]

    def _get_attributes_pool_one_party(self, user_pool, attribute_name):
        secint = mpc.SecInt(sys.maxsize.bit_length()+1)
        internal_secret = [{user_id: self._get_internal_secret(user_id, attribute_name)} for user_id in user_pool]
        internal_secret = {k: v for d in internal_secret for k, v in d.items()}
        return [(user_id, secint(internal_secret[user_id])) for user_id in user_pool]

    
    def _get_secret_attributes_one_party(self, user_pool, attribute_names):
        attribute_pool = {} 
        for attribute_name in attribute_names:
            pool_desecr = self._get_attributes_pool_one_party(user_pool, attribute_name)

            attribute_pool[attribute_name] = {}
            for user_id, attr in pool_desecr:
                attribute_pool[attribute_name][user_id] = attr
        
        return attribute_pool # {attribute_name: {user_id: attr}}

    async def _reconstruct_secret_attributes_pool(self, user_pool, attribute_name):
        secint = mpc.SecInt(sys.maxsize.bit_length()+1)
        internal_secret = [{user_id: self._get_internal_secret(user_id, attribute_name)} for user_id in user_pool]
        internal_secret = {k: v for d in internal_secret for k, v in d.items()}
        # secret sharing between TTP and SP + reconstruct secret value by adding remote secret and local secret divided by 2
        return [(user_id, mpc.sum(mpc.input(secint(internal_secret[user_id])))/2) for user_id in user_pool]

    async def _reconstruct_secret_attributes(self, user_pool, attribute_names):
        attribute_pool_desecr = {} 
        for attribute_name in attribute_names:
            pool_desecr = await self._reconstruct_secret_attributes_pool(user_pool, attribute_name)

            attribute_pool_desecr[attribute_name] = {}
            for user_id, attr in pool_desecr:
                attribute_pool_desecr[attribute_name][user_id] = attr
        
        return attribute_pool_desecr # {attribute_name: {user_id: attr}}

    async def _get_desecritized_attribute_pool(self, user_pool, attribute_names):
        if len(mpc.parties) == 1:
            return self._get_secret_attributes_one_party(user_pool, attribute_names)
        else:
            return await self._reconstruct_secret_attributes(user_pool, attribute_names)


    def _get_num_attribute_value(self, attribute_name, attribute_value):
        """
        This is a placeholder: the third party should reimplement it to match their attribute catalogue
        """

        return SENSITIVE_ATTRIBUTE_CATALOGUE[attribute_name][attribute_value]
    
    def _check_user_attributes(self, user_id, attribute_names, attribute_values, attribute_desecr_dict):
        #checks if all attribute values apply to the user
        return mpc.prod(
                (attribute_desecr_dict[attribute_name][user_id] == self._get_num_attribute_value(attribute_name, attribute_value))
                for attribute_name, attribute_value in zip(attribute_names, attribute_values)
                        )
    
    def _assert_pool_attribute_names_values(self, pool, attribute_names, attribute_values, conditionals=None):
        #assertions
        if not isinstance(attribute_names, list) and not isinstance(attribute_names, tuple):
            attribute_names = [attribute_names]
        if not isinstance(attribute_values, list) and not isinstance(attribute_values, tuple):
            attribute_values = [attribute_values]

        assert len(attribute_names) == len(attribute_values), "Number of attribute names must be equal to the number of values"

        for idx, attribute_name in enumerate(attribute_names):
            assert attribute_name in SENSITIVE_ATTRIBUTE_CATALOGUE, f"Attribute '{attribute_name}' not in catalogue"
            attribute_value = attribute_values[idx]
            assert attribute_value in SENSITIVE_ATTRIBUTE_CATALOGUE[attribute_name], f"Value '{attribute_value}' not valid for attribute '{attribute_name}'"

        if conditionals: 
            assert (len(pool) == len(conditionals)), "Size of the conditionals array needs to be equal to the size of the pool"
            pool = [p for p, cond in zip(pool, conditionals) if cond]

        return pool, attribute_names, attribute_values

    async def measure_pool_diversity(self, pool, attribute_names, attribute_values, conditionals=None):
        """
        Input fairness metric.
        Measures the fraction of members of a given protected group in a candidate pool (pool diversity).


        Parameters
        ----------
        pool : [string]
            A list of candidates: an unordered list of user IDs generated by the service provider during attribute donation.

        attribute_names : [string] | (string) | string
            The names/name of the attributes/attribute to measure diversity for, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        attribute_values : [string] | (string) | string
            The values/value of the selected attributes in attribute_names in the same order, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        conditionals : [bool], optional
            (Optional) A list indicating whether individuals at a given position in the pool should be included in the computation. 
            The implementation assumes that len(pool) == len(conditionals).

        Returns
        -------
        pool_diversity : float
            The fraction of the members of a selected group in the candidate pool. 
            A float number in the [0,1] range.
        """

        pool, attribute_names, attribute_values = self._assert_pool_attribute_names_values(pool, attribute_names, attribute_values, conditionals)

        attribute_pool_desecr = await self._get_desecritized_attribute_pool(pool, attribute_names)

        count_attr = mpc.sum(
            self._check_user_attributes(user_id, attribute_names, attribute_values, attribute_pool_desecr)
            for user_id in pool
        )
        count_attr = await mpc.output(count_attr)

        return count_attr / len(pool)


    def _normalize_browsing_model(self, browsing_model_weights):
        s = sum(browsing_model_weights)
        return [float(x)/s for x in browsing_model_weights]

    def _generate_browsing_model(self, model_name, length, param=None):
        if model_name == 'inverse_log':
            return [1 / math.log2(i + 2) for i in range(length)]
        elif model_name == 'exp_decay':
            gamma = param if param is not None else 0.8
            return [gamma ** i for i in range(length)]
        else:
            raise ValueError(f"Unsupported browsing model: {model_name}")
    
    async def measure_group_exposure(self, pool, attribute_names, attribute_values, browsing_model, browsing_param=None):
        """
        Output fairness metric. 
        Measures the exposure of members of a given protected group in a given ranking under a selected browsing model.
        

        Parameters
        ----------
        pool : [string]
            A ranked list of candidates: an ordered list of user ID generated by the service provider during attribute donation

        attribute_names : [string] | (string) | string
            The names/name of the attributes/attribute to measure group exposure for, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        attribute_values : [string] | (string) | string
            The values/value of the selected attributes in attribute_names in the same order, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        browsing_model : [float] or string
            A browsing behavior model indicating the exposure weights across ranking positions (will be normalized to sum to 1). This can be:
                - A list of floats, where each value represents the exposure weight at a given position
                - A string specifying a predefined model:
                    'inverse_log' — assigns exposure proportionally to 1 / log2(position + 2)
                    'exp_decay' — assigns exposure proportionally to gamma^position (gamma is specified via `browsing_param`, default 0.8)

        conditionals : [bool], optional
            (Optional) A list indicating whether individuals at a given position in the pool should be included in the computation. 
            The implementation assumes that len(pool) == len(conditionals).
        
        browsing_param : float, optional
            (Optional) parameter to customize browsing model, such as gamma for exp_decay
        
        Returns
        -------
        group_exposure : float
            The fraction of exposure the members of a selected group in the candidate pool get in a given ranking. 
            A float number in the [0,1] range.
        """

        pool, attribute_names, attribute_values = self._assert_pool_attribute_names_values(pool, attribute_names, attribute_values, None)

        if isinstance(browsing_model, str):
            browsing_model = self._generate_browsing_model(browsing_model, len(pool), browsing_param)

        browsing_model = self._normalize_browsing_model(browsing_model)

        if len(browsing_model) < len(pool):
            browsing_model.extend([0] * (len(pool) - len(browsing_model)))

        attribute_ranking_desecr = await self._get_desecritized_attribute_pool(pool, attribute_names)

        #self._get_num_attribute_value(attribute_name, attribute_value)
        secfxp = mpc.SecFxp(64)
        return await mpc.output(mpc.sum([
            secfxp(browsing_model[idx]) * mpc.convert(self._check_user_attributes(user_id, attribute_names, attribute_values, attribute_ranking_desecr), secfxp)
                for idx, user_id in enumerate(pool)
        ]))
    
    async def measure_topk_fairness(self, pool, attribute_names, attribute_values, k, method="skew", conditionals=None, epsilon=1e-10):
        """
        Output fairness metric.
        Supports top-k group fairness metrics including skew and discounted representation difference.

        Parameters
        ----------
        pool : [string]
            A ranked list of candidates: an ordered list of (user_id, secret_attribute_remote).

        attribute_names : [string] | (string) | string
            The names/name of the attributes/attribute to measure top-k fairness for.

        attribute_values : [string] | (string) | string
            The values/value of the selected attributes in attribute_names.

        k : int
            The cutoff rank (e.g., top-10 means k=10).

        method : string
            The fairness metric to compute. Supported options:
                - "skew" : Log ratio between group representation in top-k and expected distribution.
                - "discounted_rep_diff" : Difference in discounted representation across ranks.

        conditionals : [bool], optional
            (Optional) A list indicating whether individuals at a given position in the pool should be included in the computation. 
            The implementation assumes that len(pool) == len(conditionals).

        epsilon : float, optional
            (Optional) Small value to avoid division by zero or log(0).

        Returns
        -------
        topk_fairness : float
            The top-k fairness metric for the specified method.
        """

        pool, attribute_names, attribute_values = self._assert_pool_attribute_names_values(pool, attribute_names, attribute_values, conditionals)
        ranking_desecr = await self._get_desecritized_attribute_pool(pool, attribute_names)
        top_k_pool = pool[:k]

        def is_in_group(candidate):
            return self._check_user_attributes(candidate, attribute_names, attribute_values, ranking_desecr)

        group_indices = [is_in_group(cand) for cand in pool]
        topk_group_indices = [is_in_group(cand) for cand in top_k_pool]

        secfxp = mpc.SecFxp(64)
        sum_group_indices = mpc.convert(sum(group_indices), secfxp)
        sum_topk_group_indices = mpc.convert(sum(topk_group_indices), secfxp)

        total_group_ratio = sum_group_indices / len(pool) if pool else secfxp(0)
        topk_group_ratio = sum_topk_group_indices / k if k > 0 else secfxp(0)

        if method == "skew":
            numerator = await mpc.output(topk_group_ratio + epsilon)
            denominator = await mpc.output(total_group_ratio + epsilon)
            return math.log(numerator / denominator)

        elif method == "discounted_rep_diff":
            drd = 0.0
            for idx, cand in enumerate(top_k_pool):
                pos = idx + 1
                group_val = mpc.convert(mpc.if_else(is_in_group(cand), 1, -1), secfxp)
                drd += group_val / math.log2(pos + 1)
            
            drd = await mpc.output(drd)
            return drd

        else:
            raise ValueError(f"Unsupported top-k fairness method: {method}")
    
    async def measure_accept_rate(self, pool, pool_stage, attribute_names, attribute_values, conditionals=None):
        """
        Outcome fairnss metric. 
        For demographic parity, measure the proportion of individuals from a given protected group who are finally accepted (accept rate).
        For equal opportunity, measure the proportion of qualified individuals from a given protected group who are correctly classified (true positive rate).
        
        Parameters
        ----------
        pool : [string]
            A pool of candidates: an unordered list of user IDs generated by the service provider during attribute donation.

        pool_stage : [(string, bool, bool)]
            A pool of candidates: an unordered list of pairs (user_id, targeted, accepted), 
            where the user_id is the user ID corresponding to the pool,
            targeted is True/False indicating whether the candidate is selected as a target, 
            and accepted is True/False indicating whether the candidate actually receives positive outcomes.
            Example for demographic parity: 
                targeted: all set 1, to include all potential candidates; 
                accepted: final interview or recruitment decisions.
            Example for equal opportunity: 
                targeted: whether the candidate is qualified or not, e.g., based on evaluations by a group of experts; 
                accepted: final interview or recruitment decisions.

        attribute_names : [string] | (string) | string
            The names/name of the attributes/attribute to measure outcome fairness for, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        attribute_values : [string] | (string) | string
            The values/value of the selected attributes in attribute_names in the same order, as specified in the third party's SENSITIVE_ATTRIBUTE_CATALOGUE

        conditionals : [bool], optional
            (Optional) A list indicating whether individuals at a given position in the pool should be included in the computation. 
            The implementation assumes that len(pool) == len(conditionals).
        
        Returns
        -------
        accept rate : float
            The fraction of the members of a selected group who receive positive outcomes. 
            A float number in the [0,1] range.
        """
        
        pool, attribute_names, attribute_values = self._assert_pool_attribute_names_values(pool, attribute_names, attribute_values, conditionals)

        if conditionals:
            pool_stage = [ps for ps, cond in zip(pool_stage, conditionals) if cond]

        attribute_pool_desecr = await self._get_desecritized_attribute_pool(pool, attribute_names)
                
        stage_dict = {user: (targeted, accepted) for user, targeted, accepted in pool_stage}
        count_actual_positive, count_true_positive = 0, 0
        for user_id in pool:
            targeted, accepted = stage_dict.get(user_id, (False, False))
            count = self._check_user_attributes(user_id, attribute_names, attribute_values, attribute_pool_desecr)
            count_actual_positive += (count & targeted)
            count_true_positive += (count & (targeted & accepted))
        count_actual_positive = await mpc.output(count_actual_positive)
        count_true_positive = await mpc.output(count_true_positive)
        return count_true_positive/count_actual_positive if count_actual_positive else 0
    


    def _compute_confidence_intervals(self, p, n, N=None, confidence=0.95):

        if not (len(p) == len(n) and (N is None or len(N) == len(p))):
            raise ValueError("Lengths of p, n, and N (if provided) must be equal")
        
        z_score = norm.ppf(1 - (1 - confidence) / 2)
        SE = [np.sqrt(p[i] * (1 - p[i]) / n[i]) * (np.sqrt((N[i] - n[i]) / (N[i] - 1)) if N else 1) for i in range(len(p))]
        CI = [(p[i] - z_score * SE[i], p[i] + z_score * SE[i]) for i in range(len(p))]
        
        return CI, SE

    def _plot_confidence_intervals(self, p, n, N=None, labels=None):
        if len(p) > 20:
            raise ValueError("Maximum allowed length for p and n is 20")
        
        CI, _ = self._compute_confidence_intervals(p, n, N)
        groups = labels if labels else [f"Group {i+1}" for i in range(len(p))]
        errors = [(p[i] - CI[i][0], CI[i][1] - p[i]) for i in range(len(p))]
        
        plt.figure(figsize=(12, 5))
        colors = plt.cm.get_cmap("tab10", len(p)).colors
        
        plt.bar(groups, p, yerr=np.array(errors).T, capsize=8, color=colors, alpha=0.7)
        
        for i in range(len(groups)):
            text = f"n={n[i]}"
            if N:
                text += f"\nN={N[i]}"
            plt.text(i, p[i] + errors[i][1] + 0.02, text, ha='center', fontsize=10, color='black')

        plt.ylabel("Rate")
        plt.ylim(0, 1)
        plt.xticks(rotation=45, ha="right")
        plt.tight_layout()
        plt.show()